#include <onnxruntime_cxx_api.h>
#include <opencv2/opencv.hpp>
#include <iostream>

Ort::Env env(ORT_LOGGING_LEVEL_WARNING, "road_sign_infer");
Ort::Session* session = nullptr;

void init_model(const std::string& model_path) {
    Ort::SessionOptions session_options;
    session_options.SetIntraOpNumThreads(1);
    session = new Ort::Session(env, model_path.c_str(), session_options);
}

std::vector<float> preprocess(const cv::Mat& img) {
    cv::Mat resized;
    cv::resize(img, resized, cv::Size(224, 224));
    resized.convertTo(resized, CV_32FC3, 1.0 / 255);
    return std::vector<float>((float*)resized.data, (float*)resized.data + resized.total() * 3);
}

void infer_and_display(cv::VideoCapture& cap) {
    while (true) {
        cv::Mat frame;
        cap >> frame;
        auto input_tensor_values = preprocess(frame);

        // Create input tensor
        std::array<int64_t, 4> input_shape{1, 3, 224, 224};
        Ort::MemoryInfo memory_info = Ort::MemoryInfo::CreateCpu(
            OrtDeviceAllocator, OrtMemTypeCPU);
        Ort::Value input_tensor = Ort::Value::CreateTensor<float>(
            memory_info, input_tensor_values.data(), input_tensor_values.size(),
            input_shape.data(), input_shape.size());

        // Run inference
        const char* input_names[] = {"input"};
        const char* output_names[] = {"output"};
        auto output_tensors = session->Run(Ort::RunOptions{nullptr},
                                           input_names, &input_tensor, 1,
                                           output_names, 1);

        // Process results
        float* results = output_tensors.front().GetTensorMutableData<float>();
        // Use results to annotate frame or send over IPC
        std::cout << "Detected Sign: " << results[0] << std::endl;

        // Optional: display if on development system
        // cv::imshow("Detected", frame);
    }
}
